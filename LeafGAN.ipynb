{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation using Generative Adversarial Networks\n",
        "\n",
        "We have used GAN to generate fake diseased images of plants. The architecture of model of GAN used here is CycleGAN, which takes healthy(datasetA) and diseased(datasetB) plant images and tries to convert them into each other as A -> B, B -> A.\n",
        "\n",
        "LeafGAN is an implementation of CycleGAN, which tries to address some issues related to CycleGAN. One the major drawbacks of CycleGAN is its difficulties with the background of the plant images. The background of the image dataset we have used in this project is very consistent as they were taken in the lab environment. As a result, CycleGAN is not very efficient in creating varying backgrounds for the generated images.\n",
        "\n",
        "The solution to this problem is using only the relevant part of the leafs using a image segmentation neural network, classifying it into 3 categories:\n",
        "1. Full Leaf\n",
        "2. Partial Leaf\n",
        "3. Non Leaf\n",
        "\n",
        "The main point to be noted here is of partial leaf, which just extracts plants leaf region and discards the other parts. This has a considerable effect on the output when compared against CycleGAN.\n",
        "\n",
        "More on the LeafGAN paper can be found [here](https://arxiv.org/abs/2002.10100).\n",
        "\n",
        "We get fake diseased plant images (and fake healthy as well) from the output of this model.\n",
        "\n",
        "# Failures\n",
        "The Aim of this project was to generate fake diseased plants images, which can be used for training of image classification models.\n",
        "\n",
        "Our failure in this project was that, we tried to bite more than we could chew. We took a large dataset with varying plant diseases and species, which resulted in large number of classes when using the generated images with the image classifier.\n",
        "\n",
        "For a small scope project like this, we could have taken a particular disease for a single species which would reduced the number of classes, the classifier had to work with.\n",
        "\n",
        "As it is the case with every software project, we had changes in plan, and reduced the scope of project, to just classify the images into healthy and diseased(infected).\n",
        "\n",
        "# Difficulties\n",
        "One the major difficulties, we had to face was of hardware. As we are students and don't have access to high-end GPU's to train these beasts of models, we had to take help of google colab which disconnects after every 6 hours in the free tier."
      ],
      "metadata": {
        "id": "_aawVTu_0mBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "5TYKaHBw3h0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/AIES/LeafGAN/requirements.txt"
      ],
      "metadata": {
        "id": "rn4PKItD0GQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AIES/data/images.zip -d /content/Test\n",
        "!unzip /content/drive/MyDrive/AIES/data/train_mask.zip -d /content/Test"
      ],
      "metadata": {
        "id": "1lo6xscAnC8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir m_dir\n",
        "!cp -r /content/Test/trainA /content/m_dir\n",
        "!cp -r /content/Test/trainB /content/m_dir"
      ],
      "metadata": {
        "id": "acI6JjvxbenE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"LFLSeg_resnet101.pth\" \"https://www.dropbox.com/scl/fi/h0t2dq5rtogxvp9ufglkj/LFLSeg_resnet101.pth?rlkey=noxfamgq5387y2hbvhjirrf7j&dl=0\""
      ],
      "metadata": {
        "id": "UbofZhxdcHYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/AIES/LeafGAN/prepare_mask.py --source /content/m_dir \\\n",
        "        -p /content/LFLSeg_resnet101.pth -i 256"
      ],
      "metadata": {
        "id": "kJedFA5gbZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -0 -r /content/train_mask.zip /content/m_dir/"
      ],
      "metadata": {
        "id": "LPuJm5gTq7Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AIES/data/Test_LeafGAN.zip -d /content/drive/MyDrive/AIES/data/"
      ],
      "metadata": {
        "id": "xc8ZmMo_EYQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/AIES/LeafGAN/train.py --dataroot /content/Test \\\n",
        "        --name Test_LeafGAN --model leaf_gan --dataset_mode unaligned_masked  \\\n",
        "        --checkpoints_dir /content/drive/MyDrive/AIES/data/ --continue_train  \\\n",
        "        --epoch_count 100 --save_epoch_freq 1 --batch_size 6 --num_threads 64 \\\n",
        "        # --load_iter 16000"
      ],
      "metadata": {
        "id": "oHfhlHycK_vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MRvd3Jg0dkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification using CNN\n",
        "We have classified the images into healthy and diseased(Infected) and are testing it in the end."
      ],
      "metadata": {
        "id": "uZGeLN6t0hXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvD4gej5zb63"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AIES/data/Dataset.zip"
      ],
      "metadata": {
        "id": "Lqc8XACmzzfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths to your dataset folders\n",
        "data_dir = '/content/Dataset'  # Path to the main dataset directory\n",
        "train_dir = '/content/Train'   # Path to store the training data\n",
        "test_dir = '/content/Test'     # Path to store the testing data\n",
        "\n",
        "# Create train and test directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# List all class folders in the dataset directory\n",
        "classes = os.listdir(data_dir)\n",
        "\n",
        "# Iterate through each class folder to split into train and test\n",
        "for class_folder in classes:\n",
        "    class_path = os.path.join(data_dir, class_folder)\n",
        "    train_class_dir = os.path.join(train_dir, class_folder)\n",
        "    test_class_dir = os.path.join(test_dir, class_folder)\n",
        "\n",
        "    os.makedirs(train_class_dir, exist_ok=True)\n",
        "    os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "    images = os.listdir(class_path)\n",
        "\n",
        "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    for img in train_images:\n",
        "        src = os.path.join(class_path, img)\n",
        "        dst = os.path.join(train_class_dir, img)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    for img in test_images:\n",
        "        src = os.path.join(class_path, img)\n",
        "        dst = os.path.join(test_class_dir, img)\n",
        "        shutil.copy(src, dst)\n"
      ],
      "metadata": {
        "id": "IAQYnnxN1Yb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set up data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/Train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
        "    epochs=20,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/Test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "eval_result = model.evaluate(test_generator)\n",
        "print(\"Test accuracy:\", eval_result[1])"
      ],
      "metadata": {
        "id": "tPE7rWhU0KQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model.h5')"
      ],
      "metadata": {
        "id": "NctVO2sfAu6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from IPython.display import Image\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/AIES/data/model.h5\")\n",
        "\n",
        "# Function to preprocess the uploaded image\n",
        "def preprocess_image(image_bytes):\n",
        "    img = PILImage.open(BytesIO(image_bytes))\n",
        "    img = img.resize((150, 150))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Function to handle file upload and make predictions\n",
        "def on_upload_change(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        for filename, file_info in change['new'].items():\n",
        "            content = file_info['content']\n",
        "            img = preprocess_image(content)\n",
        "            prediction = model.predict(img)\n",
        "            result = \"Infected\" if prediction >= 0.5 else \"Healthy\"\n",
        "\n",
        "            # Display uploaded image and prediction\n",
        "            display(Image(data=content, width=150, height=150))\n",
        "            print(f\"Prediction: {result}\")\n",
        "\n",
        "# Create a file upload widget\n",
        "file_upload = widgets.FileUpload()\n",
        "\n",
        "# Attach the function to the widget's event handler\n",
        "file_upload.observe(on_upload_change)\n",
        "\n",
        "# Display the upload widget\n",
        "display(file_upload)\n"
      ],
      "metadata": {
        "id": "sud9Q-iY4VAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}